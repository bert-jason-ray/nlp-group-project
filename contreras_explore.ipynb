{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6043209d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dc/8rtfvpyj2mb6mqbnfkf5dl400000gn/T/ipykernel_41511/186667228.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprepare\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0macquire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mexplore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m#import model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/codeup-data-science/nlp-group-project/explore.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Programming Language Distribution\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mprograming_language_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macquire\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_github_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprep_github_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'readme_contents'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'musicbot'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/codeup-data-science/nlp-group-project/explore.py\u001b[0m in \u001b[0;36mprograming_language_distribution\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprograming_language_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_theme\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"white\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcountplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"language\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Set3\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'language'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Programming Language (Readme.md)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import Dict, List, Optional, Union, cast\n",
    "import requests\n",
    "import pandas as pd\n",
    "from env import github_token, github_username\n",
    "\n",
    "import prepare\n",
    "import acquire\n",
    "import explore\n",
    "#import model\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filter=\"ignore\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from mergedeep import merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47212ec",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 10px groove lightblue; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017c67c4",
   "metadata": {},
   "source": [
    "# `Acquire Data`\n",
    "## Using  [Acquire.py](https://github.com/bert-jason-ray/nlp-group-project/blob/main/acquire.py) file to bring in new dataframe.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46137f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the acquired file as new data frame\n",
    "df = acquire.get_github_data()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469de456",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 10px groove lightblue; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501b067e",
   "metadata": {},
   "source": [
    "# `Preapare Data`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce764e0a",
   "metadata": {},
   "source": [
    "## Using  [Prepare.py](https://github.com/bert-jason-ray/nlp-group-project/blob/main/prepare.py) to summon Clean, Stemmed, and Lemmatized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f4052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare.prep_github_data(df,column = 'readme_contents', extra_words=[], exclude_words=['musicbot'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8352c144",
   "metadata": {},
   "source": [
    "## Looking at the amounts of times a specific language is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40e6e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['readme_contents', 'stemmed','clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea46f9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f05eca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8109f0f",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 10px groove lightblue; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debfb460",
   "metadata": {},
   "source": [
    "# `Splitting Data`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7343afa1",
   "metadata": {},
   "source": [
    "def split_github_data(df):\n",
    "    '''\n",
    "    This function performs split on github data, stratify language.\n",
    "    Returns train, validate, and test dfs.\n",
    "    '''\n",
    "    train, test = train_test_split(df, test_size=.2, \n",
    "                                        random_state=123, stratify=df.language)\n",
    "    #train, validate = train_test_split(train_validate, test_size=.3, \n",
    "                                   #random_state=123, stratify=train_validate.language)\n",
    "\n",
    "    print('train--->', train.shape)\n",
    "    #print('validate--->', validate.shape)\n",
    "    print('test--->', test.shape)\n",
    "    return train, test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af328ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = prepare.split_github_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7efa772",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 10px groove lightblue; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ab3418",
   "metadata": {},
   "source": [
    "# `EXPLORE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10bf05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting our exploration we quickly noticed a trend of a handful of programing languages dominating our data.\n",
    "# As a result, we made the decision to focus on these main languages in an effort build a model more accurately discern between them\n",
    "def programing_language_distribution():\n",
    "    sns.set_theme(style=\"white\")\n",
    "    ax = sns.countplot(x=\"language\", data=train, palette=\"Set3\",order = train['language'].value_counts().index)\n",
    "    ax.tick_params(axis='x', rotation=90)\n",
    "    ax.set_xlabel('Programming Language (Readme.md)', size = 16)\n",
    "    ax.set_ylabel('Count / Frequency', size = 16)\n",
    "    ax.set_title(\"Programming Language Distribution\", size = 20)\n",
    "    plt.show()\n",
    "programing_language_distribution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde5572c",
   "metadata": {},
   "source": [
    "### Takeaways:\n",
    " - **JavaScript & Python seem to dominate, while Java & TypeScript and all others seem to be at the 10 range.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a400c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.language.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86e10df",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 10px groove lightblue; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c70f84a",
   "metadata": {},
   "source": [
    "## `Possible questions`**:**\n",
    "- What are key words in all `READMEs`?\n",
    "- Are there commom words in `READMEs` that all `programming languages` use?\n",
    "- Do words in `READMEs` vary based on `programming languages` used?\n",
    "- Do lenght of words vary in `READMEs` based on `programming languages`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640921f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up word counts dataframe\n",
    "all_text = ' '.join(train.lemmatized)\n",
    "javascript_text = ' '.join(train[train.language == 'JavaScript'].lemmatized)\n",
    "python_text = ' '.join(train[train.language == 'Python'].lemmatized)\n",
    "typescript_text = ' '.join(train[train.language == 'TypeScript'].lemmatized)\n",
    "java_text = ' '.join(train[train.language == 'Java'].lemmatized)\n",
    "go_text = ' '.join(train[train.language == 'Go'].lemmatized)\n",
    "kotlin_text = ' '.join(train[train.language == 'Kotlin'].lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77de5cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_top_words():\n",
    "    all_freq = pd.Series(str(all_text).split()).value_counts()\n",
    "    javascript_freq = pd.Series(str(javascript_text).split()).value_counts()\n",
    "    python_freq = pd.Series(str(python_text).split()).value_counts()\n",
    "    typeScript_freq = pd.Series(str(typescript_text).split()).value_counts()\n",
    "    java_freq = pd.Series(str(java_text).split()).value_counts()\n",
    "    go_freq = pd.Series(str(go_text).split()).value_counts()\n",
    "    kotlin_freq = pd.Series(str(kotlin_text).split()).value_counts()\n",
    "    word_counts = pd.concat([all_freq, javascript_freq, python_freq, typeScript_freq,java_freq, go_freq, kotlin_freq], sort=True, axis=1)\n",
    "    word_counts.columns = ['all', 'JavaScript', 'python', 'typescript','java', 'go', 'kotlin']\n",
    "    word_counts = word_counts.fillna(0).apply(lambda s: s.astype(int))\n",
    "    top_30 = word_counts.sort_values(by='all', ascending=False).head(30)\n",
    "    return top_30\n",
    "all_top_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2900f4",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 10px groove lightblue; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f411b020",
   "metadata": {},
   "source": [
    "# `What are key words in all READMEs & Are there commom words in READMEs that all programming languages use?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c4f987",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def word_distribution_vizual():\n",
    "    # Visualize word distribution\n",
    "    word_counts.sort_values(by='all', ascending=False)[['all','JavaScript', 'python', 'typescript','java', 'go', 'kotlin']].head(9).plot.bar()\n",
    "    plt.title('Words Used Most in README Files')\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    plt.xlabel('Nine Most Common Words Used')\n",
    "    plt.ylabel('Word Quantity')\n",
    "    plt.show()\n",
    "word_distribution_vizual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ea5b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_words_bigram_wordcloud():\n",
    "    all_D = pd.Series(str(all_text).split())\n",
    "    top_20_all_words_bigrams = (pd.Series(nltk.ngrams(all_D, 2))\n",
    "                          .value_counts()\n",
    "                          .head(20))\n",
    "    data = {k[0] + ' ' + k[1]: v for k, v in top_20_all_words_bigrams.to_dict().items()}\n",
    "    img = WordCloud(background_color='white', width=800, height=400).generate_from_frequencies(data)\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.title('Top 2 Word clusters Used')\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def all_words_bigram_barplot():\n",
    "    all_D = pd.Series(str(all_text).split())\n",
    "    top_20_all_words_bigrams = (pd.Series(nltk.ngrams(all_D, 2))\n",
    "                          .value_counts()\n",
    "                          .head(20))\n",
    "    # Top 3 Words Used in README(s)\n",
    "    top_20_all_words_bigrams.plot.bar()\n",
    "    plt.title('Top 2 Word clusters Used')\n",
    "    plt.xlabel('words')\n",
    "    plt.ylabel('')\n",
    "    plt.show()\n",
    "    \n",
    "all_words_bigram_wordcloud()\n",
    "all_words_bigram_barplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877cac53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_words_trigram_wordcloud():\n",
    "    all_D = pd.Series(str(all_text).split())\n",
    "    top_20_all_words_trigrams = (pd.Series(nltk.ngrams(all_D, 3))\n",
    "                          .value_counts()\n",
    "                          .head(20))\n",
    "    data = {k[0] + ' ' + k[1]: v for k, v in top_20_all_words_trigrams.to_dict().items()}\n",
    "    img = WordCloud(background_color='white', width=800, height=400).generate_from_frequencies(data)\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.title('Top 3 Word clusters Used')\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def all_words_trigram_barplot():\n",
    "    all_D = pd.Series(str(all_text).split())\n",
    "    top_20_all_words_trigrams = (pd.Series(nltk.ngrams(all_D, 3))\n",
    "                          .value_counts()\n",
    "                          .head(20))\n",
    "    # Top 3 Words Used in README(s)\n",
    "    top_20_all_words_trigrams.plot.bar()\n",
    "    plt.title('Top 3 Word clusters Used')\n",
    "    plt.xlabel('words')\n",
    "    plt.ylabel('')\n",
    "    plt.show()\n",
    "    \n",
    "all_words_trigram_wordcloud()\n",
    "all_words_trigram_barplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607cbc58",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 10px groove lightblue; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5f5b39",
   "metadata": {},
   "source": [
    "# `Do words in READMEs vary based on programming languages used?`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54531a3",
   "metadata": {},
   "source": [
    "**Python**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6ea50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def python_bigram_wordcloud():\n",
    "    python_D = pd.Series(str(python_text).split())\n",
    "    top_20_python_bigrams = (pd.Series(nltk.ngrams(python_D, 2))\n",
    "                          .value_counts()\n",
    "                          .head(20))\n",
    "    data = {k[0] + ' ' + k[1]: v for k, v in top_20_python_bigrams.to_dict().items()}\n",
    "    img = WordCloud(background_color='white', width=800, height=400).generate_from_frequencies(data)\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.title('Top 2 Word clusters Used')\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def python_bigram_barplot():\n",
    "    python_D = pd.Series(str(python_text).split())\n",
    "    top_20_python_bigrams = (pd.Series(nltk.ngrams(python_D, 2))\n",
    "                          .value_counts()\n",
    "                          .head(20))\n",
    "    # Top 3 Words Used in README(s)\n",
    "    top_20_python_bigrams.plot.bar()\n",
    "    plt.title('Top 2 Word clusters Used')\n",
    "    plt.xlabel('words')\n",
    "    plt.ylabel('')\n",
    "    plt.show()\n",
    "        \n",
    "python_bigram_wordcloud()\n",
    "python_bigram_barplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e38787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def python_trigram_wordcloud():\n",
    "    python_D = pd.Series(str(python_text).split())\n",
    "    top_20_python_trigrams = (pd.Series(nltk.ngrams(python_D, 3))\n",
    "                          .value_counts()\n",
    "                          .head(20))\n",
    "    data = {k[0] + ' ' + k[1]: v for k, v in top_20_python_trigrams.to_dict().items()}\n",
    "    img = WordCloud(background_color='white', width=800, height=400).generate_from_frequencies(data)\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.title('Top 3 Word clusters Used')\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def python_trigram_barplot():\n",
    "    python_D = pd.Series(str(python_text).split())\n",
    "    top_20_python_trigrams = (pd.Series(nltk.ngrams(python_D, 3))\n",
    "                          .value_counts()\n",
    "                          .head(20))\n",
    "    # Top 3 Words Used in README(s)\n",
    "    top_20_python_trigrams.plot.bar()\n",
    "    plt.title('Top 3 Word clusters Used')\n",
    "    plt.xlabel('words')\n",
    "    plt.ylabel('')\n",
    "    plt.show()\n",
    "python_trigram_wordcloud()\n",
    "python_trigram_barplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e669b5",
   "metadata": {},
   "source": [
    "***\n",
    "**JavaScript**\n",
    "- Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea033b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def javascript_bigram_wordcloud():\n",
    "    javascript_D = pd.Series(str(javascript_text).split())\n",
    "    top_20_javascript_bigrams = (pd.Series(nltk.ngrams(javascript_D, 2))\n",
    "                          .value_counts()\n",
    "                          .head(20))\n",
    "    data = {k[0] + ' ' + k[1]: v for k, v in top_20_javascript_bigrams.to_dict().items()}\n",
    "    img = WordCloud(background_color='white', width=800, height=400).generate_from_frequencies(data)\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.title('Top 2 Word clusters Used')\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def javascript_bigram_barplot():\n",
    "    javascript_D = pd.Series(str(javascript_text).split())\n",
    "    top_20_javascript_bigrams = (pd.Series(nltk.ngrams(javascript_D, 2))\n",
    "                          .value_counts()\n",
    "                          .head(20))\n",
    "    # Top 2 Words Used in README(s)\n",
    "    top_20_javascript_bigrams.plot.bar()\n",
    "    plt.title('Top 2 Word clusters Used')\n",
    "    plt.xlabel('words')\n",
    "    plt.ylabel('')\n",
    "    plt.show()\n",
    "    \n",
    "javascript_bigram_wordcloud()\n",
    "javascript_bigram_barplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572f9935",
   "metadata": {},
   "source": [
    "**JavaScript**\n",
    "- trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b770b605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def javascript_trigram_wordcloud():\n",
    "    javascript_D = pd.Series(str(javascript_text).split())\n",
    "    top_20_javascript_trigrams = (pd.Series(nltk.ngrams(javascript_D, 3))\n",
    "                          .value_counts()\n",
    "                          .head(20))\n",
    "    data = {k[0] + ' ' + k[1]: v for k, v in top_20_javascript_trigrams.to_dict().items()}\n",
    "    img = WordCloud(background_color='white', width=800, height=400).generate_from_frequencies(data)\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.title('Top 3 Word clusters Used')\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def javascript_trigram_barplot():\n",
    "    javascript_D = pd.Series(str(javascript_text).split())\n",
    "    top_20_javascript_trigrams = (pd.Series(nltk.ngrams(javascript_D, 3))\n",
    "                          .value_counts()\n",
    "                          .head(20))\n",
    "    # Top 3 Words Used in README(s)\n",
    "    top_20_javascript_trigrams.plot.bar()\n",
    "    plt.title('Top 3 Word clusters Used')\n",
    "    plt.xlabel('words')\n",
    "    plt.ylabel('')\n",
    "    plt.show()\n",
    "\n",
    "javascript_trigram_wordcloud()\n",
    "javascript_trigram_barplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6822eee",
   "metadata": {},
   "source": [
    "***\n",
    "**TypeScript**\n",
    "- Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc2d521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def typescript_bigram_wordcloud():\n",
    "    typescript_D = pd.Series(str(typescript_text).split())\n",
    "    top_20_typescript_bigrams = (pd.Series(nltk.ngrams(typescript_D, 2))\n",
    "                          .value_counts()\n",
    "                          .head(20))\n",
    "    data = {k[0] + ' ' + k[1]: v for k, v in top_20_typescript_bigrams.to_dict().items()}\n",
    "    img = WordCloud(background_color='white', width=800, height=400).generate_from_frequencies(data)\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.title('Top 2 Word clusters Used')\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def typescript_bigram_barplot():\n",
    "    typescript_D = pd.Series(str(typescript_text).split())\n",
    "    top_20_typescript_bigrams = (pd.Series(nltk.ngrams(typescript_D, 2))\n",
    "                          .value_counts()\n",
    "                          .head(20))\n",
    "    # Top 3 Words Used in README(s)\n",
    "    top_20_typescript_bigrams.plot.bar()\n",
    "    plt.title('Top 2 Word clusters Used')\n",
    "    plt.xlabel('words')\n",
    "    plt.ylabel('')\n",
    "    plt.show()\n",
    "\n",
    "typescript_bigram_wordcloud()\n",
    "typescript_bigram_barplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627e6990",
   "metadata": {},
   "source": [
    "**TypeScript**\n",
    "- trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d9b70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def typescript_trigram_wordcloud():\n",
    "    typescript_D = pd.Series(str(typescript_text).split())\n",
    "    top_20_typescript_trigrams = (pd.Series(nltk.ngrams(typescript_D, 3))\n",
    "                          .value_counts()\n",
    "                          .head(20))\n",
    "    data = {k[0] + ' ' + k[1]: v for k, v in top_20_typescript_trigrams.to_dict().items()}\n",
    "    img = WordCloud(background_color='white', width=800, height=400).generate_from_frequencies(data)\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.title('Top 3 Word clusters Used')\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def typewscript_trigram_barplot():\n",
    "    typescript_D = pd.Series(str(typescript_text).split())\n",
    "    top_20_typescript_trigrams = (pd.Series(nltk.ngrams(typescript_D, 3))\n",
    "                          .value_counts()\n",
    "                          .head(20))\n",
    "    # Top 3 Words Used in README(s)\n",
    "    top_20_typescript_trigrams.plot.bar()\n",
    "    plt.title('Top 3 Word clusters Used')\n",
    "    plt.xlabel('words')\n",
    "    plt.ylabel('')\n",
    "    plt.show()\n",
    "\n",
    "typescript_trigram_wordcloud()\n",
    "typewscript_trigram_barplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2772e58",
   "metadata": {},
   "source": [
    "***\n",
    "**Java**\n",
    "- Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce6a6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def java_bigram_wordcloud():\n",
    "    java_D = pd.Series(str(java_text).split())\n",
    "    top_20_java_bigrams = (pd.Series(nltk.ngrams(java_D, 2))\n",
    "                          .value_counts()\n",
    "                          .head(20))\n",
    "    data = {k[0] + ' ' + k[1]: v for k, v in top_20_java_bigrams.to_dict().items()}\n",
    "    img = WordCloud(background_color='white', width=800, height=400).generate_from_frequencies(data)\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.title('Top 2 Word clusters Used')\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "def java_bigram_barplot():\n",
    "    java_D = pd.Series(str(java_text).split())\n",
    "    top_20_java_bigrams = (pd.Series(nltk.ngrams(java_D, 2))\n",
    "                          .value_counts()\n",
    "                          .head(20))\n",
    "    # Top 2 Words Used in README(s)\n",
    "    top_20_java_bigrams.plot.bar()\n",
    "    plt.title('Top 2 Word clusters Used')\n",
    "    plt.xlabel('words')\n",
    "    plt.ylabel('')\n",
    "    plt.show()\n",
    "java_bigram_wordcloud()\n",
    "java_bigram_barplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104053e0",
   "metadata": {},
   "source": [
    "**Java**\n",
    "- Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf8cb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def java_trigram_wordcloud():\n",
    "    java_D = pd.Series(str(java_text).split())\n",
    "    top_20_java_trigrams = (pd.Series(nltk.ngrams(java_D, 3))\n",
    "                                  .value_counts()\n",
    "                                  .head(20))\n",
    "    data = {k[0] + ' ' + k[1]: v for k, v in top_20_java_trigrams.to_dict().items()}\n",
    "    img = WordCloud(background_color='white', width=800, height=400).generate_from_frequencies(data)\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.title('Top 3 Word clusters Used')\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "def java_trigram_barplot():\n",
    "    java_D = pd.Series(str(java_text).split())\n",
    "    top_20_java_trigrams = (pd.Series(nltk.ngrams(java_D, 3))\n",
    "                                  .value_counts()\n",
    "                                  .head(20))\n",
    "    # Top 3 Words Used in README(s)\n",
    "    top_20_java_trigrams.plot.bar()\n",
    "    plt.title('Top 3 Word clusters Used')\n",
    "    plt.xlabel('words')\n",
    "    plt.ylabel('')\n",
    "    plt.show()\n",
    "java_trigram_wordcloud()\n",
    "java_trigram_barplot()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc251f06",
   "metadata": {},
   "source": [
    "***\n",
    "**Go**\n",
    "- Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d6e6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_bigram_wordcloud():\n",
    "    go_D = pd.Series(str(go_text).split())\n",
    "    top_20_go_bigrams = (pd.Series(nltk.ngrams(go_D, 2))\n",
    "                          .value_counts()\n",
    "                          .head(20))\n",
    "    data = {k[0] + ' ' + k[1]: v for k, v in top_20_go_bigrams.to_dict().items()}\n",
    "    img = WordCloud(background_color='white', width=800, height=400).generate_from_frequencies(data)\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.title('Top 2 Word clusters Used')\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "def go_bigram_barplot():\n",
    "    go_D = pd.Series(str(go_text).split())\n",
    "    top_20_go_bigrams = (pd.Series(nltk.ngrams(go_D, 2))\n",
    "                          .value_counts()\n",
    "                          .head(20))\n",
    "    # Top 2 Words Used in README(s)\n",
    "    top_20_go_bigrams.plot.bar()\n",
    "    plt.title('Top 2 Word clusters Used')\n",
    "    plt.xlabel('words')\n",
    "    plt.ylabel('')\n",
    "    plt.show()\n",
    "    \n",
    "go_bigram_wordcloud()\n",
    "go_bigram_barplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec5a03c",
   "metadata": {},
   "source": [
    "**Go**\n",
    "- Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8867d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_trigram_wordcloud():\n",
    "    go_D = pd.Series(str(go_text).split())\n",
    "    top_20_go_trigrams = (pd.Series(nltk.ngrams(go_D, 3))\n",
    "                          .value_counts()\n",
    "                          .head(20))\n",
    "    data = {k[0] + ' ' + k[1]: v for k, v in top_20_go_trigrams.to_dict().items()}\n",
    "    img = WordCloud(background_color='white', width=800, height=400).generate_from_frequencies(data)\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.title('Top 3 Word clusters Used')\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "def go_trigram_barplot():\n",
    "    go_D = pd.Series(str(go_text).split())\n",
    "    top_20_go_trigrams = (pd.Series(nltk.ngrams(go_D, 3))\n",
    "                          .value_counts()\n",
    "                          .head(20))\n",
    "    # Top 3 Words Used in README(s)\n",
    "    top_20_go_trigrams.plot.bar()\n",
    "    plt.title('Top 3 Word clusters Used')\n",
    "    plt.xlabel('words')\n",
    "    plt.ylabel('')\n",
    "    plt.show()\n",
    "go_trigram_wordcloud()\n",
    "go_trigram_barplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2127c90b",
   "metadata": {},
   "source": [
    "***\n",
    "**UNIQUE VALUE COUNTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070f419c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_word_count():\n",
    "    # Visual of the unique word counts\n",
    "    train['unique_word_counts'] = train.lemmatized.apply(lambda x : len(set(x.split())))\n",
    "\n",
    "    unique_train = pd.DataFrame(train.groupby('language').unique_word_counts.mean().sort_values(ascending=False)).reset_index()\n",
    "    unique_train.head()\n",
    "\n",
    "    ax = sns.barplot(x='language',y='unique_word_counts',data=unique_train)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(),rotation=90)\n",
    "    plt.show()\n",
    "unique_word_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade9611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_words_in_read_mes():\n",
    "    # min README(s)\n",
    "    train.lemmatized.apply(len).sort_values().head(20).plot.bar(x=train.repo)\n",
    "    plt.title('Bottom 20 Shortest README Files')\n",
    "    plt.xlabel('Repository (Index Number)')\n",
    "    plt.ylabel('')\n",
    "    plt.show()\n",
    "min_words_in_read_mes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603d7b22",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 10px groove lightblue; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9953f385",
   "metadata": {},
   "source": [
    "# `Do lenght of words vary in READMEs based on programming languages?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66335bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
