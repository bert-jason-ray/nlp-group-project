{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5de86885",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "# DummyClassifier from sklearn is used to create a baseline accuracy.\n",
    "from sklearn.dummy import DummyClassifier \n",
    "# TfidfVectorizer is used to create a sparce matrices of tf-idf scores to run through modeling\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Import to split the data into train, test, split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Import to model the data\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Import to understand the data modeling scores\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import acquire\n",
    "import prepare\n",
    "import pandas as pd\n",
    "rs = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89a88c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = acquire.get_github_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c8e024e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data by creating clean, stemmed and lemmatized columns\n",
    "df = prepare.prep_github_data(df, column='readme_contents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0022880f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train---> (89, 6)\n",
      "validate---> (39, 6)\n",
      "test---> (32, 6)\n"
     ]
    }
   ],
   "source": [
    "train, validate, test = prepare.split_github_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21dc76ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JavaScript    0.42500\n",
       "Python        0.36250\n",
       "not_top       0.14375\n",
       "TypeScript    0.06875\n",
       "Name: language, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates a list of top three languages from dataframe\n",
    "top_languages = ['JavaScript','Python','TypeScript']\n",
    "# Create a new version of our df to transform for modeling\n",
    "model = df.copy()\n",
    "# Rename the languages that are not in the top three \"not_top\"\n",
    "model['language'] = model.language.apply(lambda lang : lang if lang in top_languages else \"not_top\")\n",
    "# show the distribution\n",
    "model.language.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39709d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 43%\n"
     ]
    }
   ],
   "source": [
    "# baseline prediction\n",
    "print(f'Baseline Accuracy: {round(max(train.language.value_counts()) / train.shape[0] *100)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "221c159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the tf-idf model\n",
    "tfidf = TfidfVectorizer()\n",
    "# Fit the model and create the X, y variables for modeling\n",
    "X = tfidf.fit_transform(model.lemmatized)\n",
    "y = model.language \n",
    "# Split the data into train (55%) validate (24%) test (20%) split\n",
    "X_train_validate, X_test, y_train_validate, y_test = train_test_split(X, y, stratify=y, test_size=.2, random_state = rs)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_validate, y_train_validate, stratify=y_train_validate, test_size=.3, random_state = rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df08c530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Result Dataframes to store actual and predictive scores from the models\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "test = pd.DataFrame(dict(actual=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2699ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit each model\n",
    "lm = LogisticRegression(multi_class='multinomial',random_state=rs).fit(X_train, y_train)\n",
    "dtc = DecisionTreeClassifier(max_depth=4, random_state=rs).fit(X_train, y_train)\n",
    "rf = RandomForestClassifier(min_samples_leaf=3,max_depth=4, random_state=rs).fit(X_train,y_train)\n",
    "knn = KNeighborsClassifier().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2c32f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the train predictions in our result df\n",
    "train['lm_predicted'] = lm.predict(X_train)\n",
    "train['dtc_predicted'] = dtc.predict(X_train)\n",
    "train['rf_predicted'] = rf.predict(X_train)\n",
    "train['knn_predicted'] = knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7c65489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 82.02%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual        JavaScript  Python  TypeScript  not_top\n",
      "lm_predicted                                         \n",
      "JavaScript            38       1           6        8\n",
      "Python                 0      31           0        1\n",
      "not_top                0       0           0        4\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  JavaScript       0.72      1.00      0.84        38\n",
      "      Python       0.97      0.97      0.97        32\n",
      "  TypeScript       0.00      0.00      0.00         6\n",
      "     not_top       1.00      0.31      0.47        13\n",
      "\n",
      "    accuracy                           0.82        89\n",
      "   macro avg       0.67      0.57      0.57        89\n",
      "weighted avg       0.80      0.82      0.77        89\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.lm_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.lm_predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.lm_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ef82b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 76.40%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual         JavaScript  Python  TypeScript  not_top\n",
      "dtc_predicted                                         \n",
      "JavaScript             38       8           6        4\n",
      "Python                  0      24           0        3\n",
      "not_top                 0       0           0        6\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  JavaScript       0.68      1.00      0.81        38\n",
      "      Python       0.89      0.75      0.81        32\n",
      "  TypeScript       0.00      0.00      0.00         6\n",
      "     not_top       1.00      0.46      0.63        13\n",
      "\n",
      "    accuracy                           0.76        89\n",
      "   macro avg       0.64      0.55      0.56        89\n",
      "weighted avg       0.76      0.76      0.73        89\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Decision Tree Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.dtc_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.dtc_predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.dtc_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c33232d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 71.91%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual        JavaScript  Python  TypeScript  not_top\n",
      "rf_predicted                                         \n",
      "JavaScript            38       8           5       10\n",
      "Python                 0      24           0        2\n",
      "TypeScript             0       0           1        0\n",
      "not_top                0       0           0        1\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  JavaScript       0.62      1.00      0.77        38\n",
      "      Python       0.92      0.75      0.83        32\n",
      "  TypeScript       1.00      0.17      0.29         6\n",
      "     not_top       1.00      0.08      0.14        13\n",
      "\n",
      "    accuracy                           0.72        89\n",
      "   macro avg       0.89      0.50      0.51        89\n",
      "weighted avg       0.81      0.72      0.67        89\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.rf_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.rf_predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.rf_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "712f6649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 69.66%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual         JavaScript  Python  TypeScript  not_top\n",
      "knn_predicted                                         \n",
      "JavaScript             32      10           3        5\n",
      "Python                  4      22           0        2\n",
      "TypeScript              1       0           3        1\n",
      "not_top                 1       0           0        5\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  JavaScript       0.64      0.84      0.73        38\n",
      "      Python       0.79      0.69      0.73        32\n",
      "  TypeScript       0.60      0.50      0.55         6\n",
      "     not_top       0.83      0.38      0.53        13\n",
      "\n",
      "    accuracy                           0.70        89\n",
      "   macro avg       0.71      0.60      0.63        89\n",
      "weighted avg       0.72      0.70      0.69        89\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('KNN Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.knn_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.knn_predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.knn_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2a5f69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the validate predictions to the results df\n",
    "validate['lm_predicted'] = lm.predict(X_validate)\n",
    "validate['dtc_predicted'] = dtc.predict(X_validate)\n",
    "validate['rf_predicted'] = rf.predict(X_validate)\n",
    "validate['knn_predicted'] = knn.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "527f3db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 58.97%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual        JavaScript  Python  TypeScript  not_top\n",
      "lm_predicted                                         \n",
      "JavaScript            16       7           3        4\n",
      "Python                 1       7           0        1\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  JavaScript       0.53      0.94      0.68        17\n",
      "      Python       0.78      0.50      0.61        14\n",
      "  TypeScript       0.00      0.00      0.00         3\n",
      "     not_top       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.59        39\n",
      "   macro avg       0.33      0.36      0.32        39\n",
      "weighted avg       0.51      0.59      0.52        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.lm_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(validate.lm_predicted, validate.actual))\n",
    "print('---')\n",
    "print(classification_report(validate.actual, validate.lm_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1530d81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 56.41%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual         JavaScript  Python  TypeScript  not_top\n",
      "dtc_predicted                                         \n",
      "JavaScript             16       7           1        4\n",
      "Python                  0       5           1        0\n",
      "not_top                 1       2           1        1\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  JavaScript       0.57      0.94      0.71        17\n",
      "      Python       0.83      0.36      0.50        14\n",
      "  TypeScript       0.00      0.00      0.00         3\n",
      "     not_top       0.20      0.20      0.20         5\n",
      "\n",
      "    accuracy                           0.56        39\n",
      "   macro avg       0.40      0.37      0.35        39\n",
      "weighted avg       0.57      0.56      0.52        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Decision Tree Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.dtc_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(validate.dtc_predicted, validate.actual))\n",
    "print('---')\n",
    "print(classification_report(validate.actual, validate.dtc_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b759696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 56.41%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual        JavaScript  Python  TypeScript  not_top\n",
      "rf_predicted                                         \n",
      "JavaScript            17       9           3        4\n",
      "Python                 0       5           0        1\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  JavaScript       0.52      1.00      0.68        17\n",
      "      Python       0.83      0.36      0.50        14\n",
      "  TypeScript       0.00      0.00      0.00         3\n",
      "     not_top       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.56        39\n",
      "   macro avg       0.34      0.34      0.29        39\n",
      "weighted avg       0.52      0.56      0.48        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.rf_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(validate.rf_predicted, validate.actual))\n",
    "print('---')\n",
    "print(classification_report(validate.actual, validate.rf_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3758e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 69.23%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual         JavaScript  Python  TypeScript  not_top\n",
      "knn_predicted                                         \n",
      "JavaScript             14       4           1        1\n",
      "Python                  2      10           1        1\n",
      "not_top                 1       0           1        3\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  JavaScript       0.70      0.82      0.76        17\n",
      "      Python       0.71      0.71      0.71        14\n",
      "  TypeScript       0.00      0.00      0.00         3\n",
      "     not_top       0.60      0.60      0.60         5\n",
      "\n",
      "    accuracy                           0.69        39\n",
      "   macro avg       0.50      0.53      0.52        39\n",
      "weighted avg       0.64      0.69      0.66        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('KNN Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.knn_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(validate.knn_predicted, validate.actual))\n",
    "print('---')\n",
    "print(classification_report(validate.actual, validate.knn_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "055ddd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the predicitons to the results df\n",
    "test['lm_predicted'] = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94648995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 50.00%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual        JavaScript  Python  TypeScript  not_top\n",
      "lm_predicted                                         \n",
      "JavaScript            11       7           1        5\n",
      "Python                 2       5           1        0\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  JavaScript       0.46      0.85      0.59        13\n",
      "      Python       0.62      0.42      0.50        12\n",
      "  TypeScript       0.00      0.00      0.00         2\n",
      "     not_top       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.50        32\n",
      "   macro avg       0.27      0.32      0.27        32\n",
      "weighted avg       0.42      0.50      0.43        32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.lm_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(test.lm_predicted, test.actual))\n",
    "print('---')\n",
    "print(classification_report(test.actual, test.lm_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3da994",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
